{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# House Price Prediction\n\n**About the Dataset:**\n\nThe dataset used for this project is the **[Boston House Prices Dataset](https://www.kaggle.com/datasets/vikrishnan/boston-house-prices/data)**, which contains information about various attributes related to Boston suburbs and towns. These records were collected from the Boston Standard Metropolitan Statistical Area (SMSA) in 1970.\n\n**Attributes in the Dataset:**\n\n- **CRIM**: Per capita crime rate by town.\n\n- **ZN**: Proportion of residential land zoned for lots over 25,000 sq.ft.\n\n- **INDUS**: Proportion of non-retail business acres per town.\n\n- **CHAS**: Charles River dummy variable (1 if tract bounds river; 0 otherwise).\n\n- **NOX**: Nitric oxides concentration (parts per 10 million).\n\n- **RM**: Average number of rooms per dwelling.\n\n- **AGE**: Proportion of owner-occupied units built before 1940.\n\n- **DIS**: Weighted distances to five Boston employment centers.\n\n- **RAD**: Index of accessibility to radial highways.\n\n- **TAX**: Full-value property-tax rate per $10,000.\n\n- **PTRATIO**: Pupil-teacher ratio by town.\n\n- **B**: A derived feature, calculated as 1000 * (Bk - 0.63)^2, where Bk is the proportion of Black residents by town.\n\n- **LSTAT**: Percentage of lower status population.\n\n- **MEDV**: Median value of owner-occupied homes in $1000s.\n\n","metadata":{"id":"8X2orekaCcvM"}},{"cell_type":"markdown","source":"## Import the necessary libraries:","metadata":{"id":"LrnxT-9jEx-A"}},{"cell_type":"code","source":"import os\nimport sys\nimport random\nimport time\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats","metadata":{"id":"Hpf_r5wm_aSr","execution":{"iopub.status.busy":"2023-10-04T11:49:51.994742Z","iopub.execute_input":"2023-10-04T11:49:51.995521Z","iopub.status.idle":"2023-10-04T11:49:52.955672Z","shell.execute_reply.started":"2023-10-04T11:49:51.995475Z","shell.execute_reply":"2023-10-04T11:49:52.954782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"id":"HQvoYG6wse8b","execution":{"iopub.status.busy":"2023-10-04T11:49:52.957510Z","iopub.execute_input":"2023-10-04T11:49:52.958053Z","iopub.status.idle":"2023-10-04T11:49:52.961635Z","shell.execute_reply.started":"2023-10-04T11:49:52.958031Z","shell.execute_reply":"2023-10-04T11:49:52.960646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading DataSet:\n","metadata":{"id":"BrQWwjjWrD-Z"}},{"cell_type":"code","source":"column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']","metadata":{"id":"ohiADWQqs8RM","execution":{"iopub.status.busy":"2023-10-04T11:49:52.962637Z","iopub.execute_input":"2023-10-04T11:49:52.963091Z","iopub.status.idle":"2023-10-04T11:49:52.973338Z","shell.execute_reply.started":"2023-10-04T11:49:52.963062Z","shell.execute_reply":"2023-10-04T11:49:52.972650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path=\"/kaggle/input/boston-house-prices/housing.csv\"\ndf=pd.read_csv(path,header=None, delimiter=r\"\\s+\", names=column_names)","metadata":{"id":"3iu041HTrBfZ","execution":{"iopub.status.busy":"2023-10-04T11:49:52.974139Z","iopub.execute_input":"2023-10-04T11:49:52.974398Z","iopub.status.idle":"2023-10-04T11:49:53.001936Z","shell.execute_reply.started":"2023-10-04T11:49:52.974380Z","shell.execute_reply":"2023-10-04T11:49:53.001370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"id":"9gJfwexSFBIT","outputId":"e80ec3f7-a030-4c43-bf3c-e6ebf3913086","execution":{"iopub.status.busy":"2023-10-04T11:49:53.003790Z","iopub.execute_input":"2023-10-04T11:49:53.005077Z","iopub.status.idle":"2023-10-04T11:49:53.031385Z","shell.execute_reply.started":"2023-10-04T11:49:53.005055Z","shell.execute_reply":"2023-10-04T11:49:53.030661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"id":"yQ2z5pcesJJp","outputId":"3df68049-5374-4e58-d8f1-54fcb8d1ebd7","execution":{"iopub.status.busy":"2023-10-04T11:49:53.032718Z","iopub.execute_input":"2023-10-04T11:49:53.033043Z","iopub.status.idle":"2023-10-04T11:49:53.038335Z","shell.execute_reply.started":"2023-10-04T11:49:53.033015Z","shell.execute_reply":"2023-10-04T11:49:53.037542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe(include='all')","metadata":{"id":"9PFlS6J6uDC4","outputId":"6c5f799b-ce42-475a-fd35-51f4eb9fbb10","execution":{"iopub.status.busy":"2023-10-04T11:49:53.039655Z","iopub.execute_input":"2023-10-04T11:49:53.040407Z","iopub.status.idle":"2023-10-04T11:49:53.082280Z","shell.execute_reply.started":"2023-10-04T11:49:53.040378Z","shell.execute_reply":"2023-10-04T11:49:53.081718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"id":"gJ4PtrVwuFgU","outputId":"05bc49f4-84a9-40d2-cfc1-cfde272c5968","execution":{"iopub.status.busy":"2023-10-04T11:49:53.083064Z","iopub.execute_input":"2023-10-04T11:49:53.083457Z","iopub.status.idle":"2023-10-04T11:49:53.103495Z","shell.execute_reply.started":"2023-10-04T11:49:53.083430Z","shell.execute_reply":"2023-10-04T11:49:53.102623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"id":"UiccEpvjuZcb","outputId":"d476d7d5-f895-4429-a64f-c2e3eddd9d93","execution":{"iopub.status.busy":"2023-10-04T11:49:53.104531Z","iopub.execute_input":"2023-10-04T11:49:53.105251Z","iopub.status.idle":"2023-10-04T11:49:53.115610Z","shell.execute_reply.started":"2023-10-04T11:49:53.105232Z","shell.execute_reply":"2023-10-04T11:49:53.114929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No missing values","metadata":{"id":"-pZcS51KuplQ"}},{"cell_type":"code","source":"miss_val=df.isnull().sum().sort_values(ascending=False)\nmiss_val=pd.DataFrame(data=df.isnull().sum().sort_values(ascending=False), columns=['MissValueCount'])\n\nmiss_val['Percent']=miss_val.MissValueCount.apply(lambda x:'{:.2f}'.format(float(x)/df.shape[0]*100))\nmiss_val=miss_val[miss_val.MissValueCount>=0]\nmiss_val","metadata":{"id":"-n-JpE-WupMN","outputId":"415a9e03-55cc-42d1-8459-934c6a37d6bc","execution":{"iopub.status.busy":"2023-10-04T11:49:53.116469Z","iopub.execute_input":"2023-10-04T11:49:53.116785Z","iopub.status.idle":"2023-10-04T11:49:53.130666Z","shell.execute_reply.started":"2023-10-04T11:49:53.116757Z","shell.execute_reply":"2023-10-04T11:49:53.130187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(df.MEDV)","metadata":{"id":"Kp1gUfRUumxZ","outputId":"a089b595-5e17-462a-b4eb-c17c1ac81279","execution":{"iopub.status.busy":"2023-10-04T11:49:53.131475Z","iopub.execute_input":"2023-10-04T11:49:53.132167Z","iopub.status.idle":"2023-10-04T11:49:53.453662Z","shell.execute_reply.started":"2023-10-04T11:49:53.132139Z","shell.execute_reply":"2023-10-04T11:49:53.452761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initial Data Observations and Considerations\n\nIn the initial exploration of the dataset, several interesting observations and considerations have been identified that can inform our approach to the house price prediction task. These observations are as follows:\n\n### 1. ZN (Proportion of Residential Land Zoned for Large Lots)\n- The 25th and 50th percentiles of the 'ZN' column have values of 0, indicating that a significant portion of the data may have zero values for this feature.\n- It's reasonable to assume that this variable might not have a strong influence on house prices if most values are zero.\n\n### 2. CHAS (Charles River Dummy Variable)\n- The 25th, 50th, and 75th percentiles of the 'CHAS' column are all 0, suggesting that this binary categorical variable might not have a significant impact on house prices in this dataset.\n\n### 3. MEDV (Median Value of Owner-Occupied Homes)\n- The maximum value of 'MEDV' is 50, and it is noted that the data description indicates that this variable is censored at 50.00, corresponding to a median price of $50,000.\n- Values above 50 may not provide useful information for predicting house prices, and this censoring should be considered when building the regression model.\n\nThese initial observations guide our data preprocessing decisions, including the potential exclusion of the 'ZN' and 'CHAS' columns from our feature set and the handling of 'MEDV' values above 50. Furthermore, we will visualize the data to explore trends and relationships with the target variable ('MEDV') for a more comprehensive analysis.\n\nData exploration and understanding are fundamental steps in preparing the dataset for modeling and making informed decisions throughout the project.\n","metadata":{"id":"drjqPgg3yqvc"}},{"cell_type":"code","source":"fig, axs = plt.subplots(ncols=7, nrows=2, figsize=(20, 10))\nindex = 0\naxs = axs.flatten()\nfor k,v in df.items():\n    sns.boxplot(y=k, data=df, ax=axs[index])\n    index += 1\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)","metadata":{"id":"5W9r_jnlxC9F","outputId":"da5b7ce8-069d-4f5d-dda8-6a8a89415ba6","execution":{"iopub.status.busy":"2023-10-04T11:49:53.454606Z","iopub.execute_input":"2023-10-04T11:49:53.454811Z","iopub.status.idle":"2023-10-04T11:49:54.971714Z","shell.execute_reply.started":"2023-10-04T11:49:53.454793Z","shell.execute_reply":"2023-10-04T11:49:54.970902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Columns like CRIM, ZN, RM, B seems to have outliers. Let's see the outliers percentage in every column.","metadata":{"id":"_uiYfdFKzzqy"}},{"cell_type":"code","source":"for k, v in df.items():\n        q1 = v.quantile(0.25)\n        q3 = v.quantile(0.75)\n        irq = q3 - q1\n        v_col = v[(v <= q1 - 1.5 * irq) | (v >= q3 + 1.5 * irq)]\n        perc = np.shape(v_col)[0] * 100.0 / np.shape(df)[0]\n        print(\"Column %s outliers = %.2f%%\" % (k, perc))","metadata":{"id":"UVP3nYsWzR3O","outputId":"cdc29e38-9902-477b-d468-f62621c83877","execution":{"iopub.status.busy":"2023-10-04T11:49:54.973502Z","iopub.execute_input":"2023-10-04T11:49:54.974132Z","iopub.status.idle":"2023-10-04T11:49:55.002561Z","shell.execute_reply.started":"2023-10-04T11:49:54.974099Z","shell.execute_reply":"2023-10-04T11:49:55.001765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's remove MEDV outliers (MEDV = 50.0) before plotting more distributions","metadata":{"id":"J8aX-kmp0NEo"}},{"cell_type":"code","source":"data = df[~(df['MEDV'] >= 50.0)]\nprint(np.shape(data))","metadata":{"id":"_1YCpap4z5W_","outputId":"879d19b0-7cb3-43ac-c977-f107bad139b6","execution":{"iopub.status.busy":"2023-10-04T11:49:55.006704Z","iopub.execute_input":"2023-10-04T11:49:55.006931Z","iopub.status.idle":"2023-10-04T11:49:55.011483Z","shell.execute_reply.started":"2023-10-04T11:49:55.006902Z","shell.execute_reply":"2023-10-04T11:49:55.010955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see how these features plus MEDV distributions looks like","metadata":{"id":"dL_UftNr1mfh"}},{"cell_type":"code","source":"fig, axs = plt.subplots(ncols=7, nrows=2, figsize=(20, 10))\nindex = 0\naxs = axs.flatten()\nfor k,v in data.items():\n    sns.distplot(v, ax=axs[index])\n    index += 1\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)","metadata":{"id":"v4NnzpZ21fNV","outputId":"26b70486-1eba-4977-8803-b91f33910e16","execution":{"iopub.status.busy":"2023-10-04T11:49:55.012087Z","iopub.execute_input":"2023-10-04T11:49:55.012292Z","iopub.status.idle":"2023-10-04T11:49:58.229316Z","shell.execute_reply.started":"2023-10-04T11:49:55.012274Z","shell.execute_reply":"2023-10-04T11:49:58.228413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The histogram also shows that columns CRIM, ZN, B has highly skewed distributions. Also MEDV looks to have a normal distribution (the predictions) and other colums seem to have norma or bimodel ditribution of data except CHAS (which is a discrete variable).\n\nNow let's plot the pairwise correlation on data.","metadata":{"id":"yGtkWLjG1_3c"}},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nsns.heatmap(df.corr().abs(),  annot=True, cmap='viridis')\nplt.title(\"Correlation HeatMap\")\nplt.show()","metadata":{"id":"GQ4XfV8-15j1","outputId":"877b314d-137a-490c-e5ed-8177e88d9974","execution":{"iopub.status.busy":"2023-10-04T11:49:58.230409Z","iopub.execute_input":"2023-10-04T11:49:58.231026Z","iopub.status.idle":"2023-10-04T11:49:58.890631Z","shell.execute_reply.started":"2023-10-04T11:49:58.230995Z","shell.execute_reply":"2023-10-04T11:49:58.889626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From correlation matrix, we see TAX and RAD are highly correlated features. The columns LSTAT, INDUS, RM, TAX, NOX, PTRAIO has a correlation score above 0.5 with MEDV which is a good indication of using as predictors. Let's plot these columns against MEDV.","metadata":{"id":"rJjm_CvG25sD"}},{"cell_type":"code","source":"y = df['MEDV']\ncolumn_sels = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']","metadata":{"id":"zKjiEeuFkaRL","execution":{"iopub.status.busy":"2023-10-04T11:49:58.891782Z","iopub.execute_input":"2023-10-04T11:49:58.892121Z","iopub.status.idle":"2023-10-04T11:49:58.896646Z","shell.execute_reply.started":"2023-10-04T11:49:58.892098Z","shell.execute_reply":"2023-10-04T11:49:58.895762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\n# Let's scale the columns before plotting them against MEDV\nmin_max_scaler = preprocessing.MinMaxScaler()\ncolumn_sels = ['LSTAT', 'INDUS', 'NOX', 'PTRATIO', 'RM', 'TAX', 'DIS', 'AGE']\nx = data.loc[:,column_sels]\ny = data['MEDV']\nx = pd.DataFrame(data=min_max_scaler.fit_transform(x), columns=column_sels)\nfig, axs = plt.subplots(ncols=4, nrows=2, figsize=(20, 10))\nindex = 0\naxs = axs.flatten()\nfor i, k in enumerate(column_sels):\n    sns.regplot(y=y, x=x[k], ax=axs[i])\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)","metadata":{"id":"Dmbwu9QC4diX","outputId":"5c675d7b-9254-4de5-e49d-840beeb43741","execution":{"iopub.status.busy":"2023-10-04T11:49:58.897826Z","iopub.execute_input":"2023-10-04T11:49:58.898252Z","iopub.status.idle":"2023-10-04T11:50:01.172878Z","shell.execute_reply.started":"2023-10-04T11:49:58.898230Z","shell.execute_reply":"2023-10-04T11:50:01.171939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize the relationships between the scaled features ('LSTAT', 'INDUS', 'NOX', 'PTRATIO', 'RM', 'TAX', 'DIS', 'AGE') and the target variable 'MEDV' using regression plots. Scaling the features to a common range ([0, 1]) ensures that they are on a similar scale and helps in comparing their effects on the target variable. These regression plots can provide insights into how each feature influences the target variable in a standardized way.visualize the relationships between the scaled features ('LSTAT', 'INDUS', 'NOX', 'PTRATIO', 'RM', 'TAX', 'DIS', 'AGE') and the target variable 'MEDV' using regression plots. Scaling the features to a common range ([0, 1]) ensures that they are on a similar scale and helps in comparing their effects on the target variable. These regression plots can provide insights into how each feature influences the target variable in a standardized way.","metadata":{"id":"eaTqRNWx4Axg"}},{"cell_type":"markdown","source":"So with these analsis, we may try predict MEDV with 'LSTAT', 'INDUS', 'NOX', 'PTRATIO', 'RM', 'TAX', 'DIS', 'AGE' features. Let's try to remove the skewness of the data trough log transformation.","metadata":{"id":"mgAT62JS43WM"}},{"cell_type":"code","source":"df.skew().sort_values(ascending=False)","metadata":{"id":"NDankpND52s5","outputId":"b6e42553-2fe8-421a-fb9d-1a56080ec243","execution":{"iopub.status.busy":"2023-10-04T11:50:01.174149Z","iopub.execute_input":"2023-10-04T11:50:01.174424Z","iopub.status.idle":"2023-10-04T11:50:01.183163Z","shell.execute_reply.started":"2023-10-04T11:50:01.174402Z","shell.execute_reply":"2023-10-04T11:50:01.182230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y =  np.log1p(y)\nfor col in x.columns:\n    if np.abs(x[col].skew()) > 0.3:\n        x[col] = np.log1p(x[col])","metadata":{"id":"LH3klO3C5CGM","execution":{"iopub.status.busy":"2023-10-04T11:50:01.184369Z","iopub.execute_input":"2023-10-04T11:50:01.184666Z","iopub.status.idle":"2023-10-04T11:50:01.197691Z","shell.execute_reply.started":"2023-10-04T11:50:01.184638Z","shell.execute_reply":"2023-10-04T11:50:01.197072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split the Dataset into train and test data","metadata":{"id":"qasdifxn6NPj"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into training and testing sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=3)","metadata":{"id":"rNC6qVyb5GW5","execution":{"iopub.status.busy":"2023-10-04T11:50:01.198660Z","iopub.execute_input":"2023-10-04T11:50:01.198934Z","iopub.status.idle":"2023-10-04T11:50:01.296664Z","shell.execute_reply.started":"2023-10-04T11:50:01.198892Z","shell.execute_reply":"2023-10-04T11:50:01.295989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\n# Create a Linear Regression model instance\nlr = LinearRegression()\n\n# Fit the model to your training data\nlr.fit(x_train, y_train)","metadata":{"id":"Xcq7HxCv6rDf","outputId":"d1428988-a3ee-410e-ea2d-0992d5abe2fe","execution":{"iopub.status.busy":"2023-10-04T11:50:01.297734Z","iopub.execute_input":"2023-10-04T11:50:01.297965Z","iopub.status.idle":"2023-10-04T11:50:01.400175Z","shell.execute_reply.started":"2023-10-04T11:50:01.297947Z","shell.execute_reply":"2023-10-04T11:50:01.399226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = lr.predict(x_test)\nprint(\"Predicted Values:\", y_pred)","metadata":{"id":"55BOhVL_8Ao5","outputId":"f96c786e-c0da-4e1a-fac2-5ff442119cdc","execution":{"iopub.status.busy":"2023-10-04T11:50:01.401015Z","iopub.execute_input":"2023-10-04T11:50:01.401286Z","iopub.status.idle":"2023-10-04T11:50:01.407544Z","shell.execute_reply.started":"2023-10-04T11:50:01.401268Z","shell.execute_reply":"2023-10-04T11:50:01.406786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# Calculate the metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\nr2 = r2_score(y_test, y_pred)\n\n# Print the metrics\nprint(\"Linear Regression Model: \")\nprint(\"Mean Absolute Error (MAE):\", mae)\nprint(\"Mean Squared Error (MSE):\", mse)\nprint(\"Root Mean Squared Error (RMSE):\", rmse)\nprint(\"R-squared (R2) Score:\", r2)","metadata":{"id":"HCyhSng-8uI4","outputId":"58689772-cf7e-417d-c5ec-d0cfdfef742f","execution":{"iopub.status.busy":"2023-10-04T11:50:01.408661Z","iopub.execute_input":"2023-10-04T11:50:01.409066Z","iopub.status.idle":"2023-10-04T11:50:01.418740Z","shell.execute_reply.started":"2023-10-04T11:50:01.409037Z","shell.execute_reply":"2023-10-04T11:50:01.418157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coefficients = lr.coef_\nintercept = lr.intercept_\n\n# Print the coefficients (weights) for each feature\nprint(\"Coefficients (Weights) for each feature:\")\nfor feature, coef in zip(x_train.columns, coefficients):\n    print(f\"{feature}: {coef}\")\n\n# Print the intercept\nprint(\"Intercept (Bias):\", intercept)","metadata":{"id":"3Aa5sDKD8z2g","outputId":"39fd2c75-2c70-44c2-91be-b320d37187bd","execution":{"iopub.status.busy":"2023-10-04T11:50:01.419593Z","iopub.execute_input":"2023-10-04T11:50:01.419841Z","iopub.status.idle":"2023-10-04T11:50:01.430204Z","shell.execute_reply.started":"2023-10-04T11:50:01.419821Z","shell.execute_reply":"2023-10-04T11:50:01.429299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualization of Regression model:\n","metadata":{"id":"ydiKaFvv9tFf"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Scatter plot\nplt.scatter(y_test, y_pred)\nplt.xlabel(\"Actual Values\")\nplt.ylabel(\"Predicted Values\")\nplt.title(\"Actual vs. Predicted Values\")\n\n# Add a regression line (optional)\nplt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red')\n\nplt.show()","metadata":{"id":"c9xmCMQS84tG","outputId":"78333533-bb4c-4b14-f2f0-2c2bf1fc5f2d","execution":{"iopub.status.busy":"2023-10-04T11:50:01.431333Z","iopub.execute_input":"2023-10-04T11:50:01.431583Z","iopub.status.idle":"2023-10-04T11:50:01.646568Z","shell.execute_reply.started":"2023-10-04T11:50:01.431545Z","shell.execute_reply":"2023-10-04T11:50:01.645768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM Model:","metadata":{"id":"5dRFLhrF-z2o"}},{"cell_type":"code","source":"from sklearn.svm import SVR\nsvr_model = SVR(kernel='rbf')\nsvr_model.fit(x_train, y_train)","metadata":{"id":"gcW8eSRK9yz-","outputId":"3278ff6e-1099-493f-cfeb-66b46b647df8","execution":{"iopub.status.busy":"2023-10-04T11:50:01.647678Z","iopub.execute_input":"2023-10-04T11:50:01.648205Z","iopub.status.idle":"2023-10-04T11:50:01.662804Z","shell.execute_reply.started":"2023-10-04T11:50:01.648176Z","shell.execute_reply":"2023-10-04T11:50:01.661847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = svr_model.predict(x_test)\nprint(\"Predicted Values:\", y_pred)","metadata":{"id":"bnba5OEu-99k","outputId":"616623a6-b3ff-4dbd-e515-8bb4d6691f8c","execution":{"iopub.status.busy":"2023-10-04T11:50:01.663760Z","iopub.execute_input":"2023-10-04T11:50:01.664247Z","iopub.status.idle":"2023-10-04T11:50:01.670876Z","shell.execute_reply.started":"2023-10-04T11:50:01.664225Z","shell.execute_reply":"2023-10-04T11:50:01.670043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\n\n# Print the metrics\nprint(\"SVM MODEL Metrics: \")\nprint(\"Mean Absolute Error (MAE):\", mae)\nprint(\"Mean Squared Error (MSE):\", mse)\nprint(\"Root Mean Squared Error (RMSE):\", rmse)\nprint(\"R-squared (R2) Score:\", r2)","metadata":{"id":"6AXWZ_cI--v8","outputId":"12d01c5e-320e-4cee-ea31-bd014c919004","execution":{"iopub.status.busy":"2023-10-04T11:50:01.671650Z","iopub.execute_input":"2023-10-04T11:50:01.671914Z","iopub.status.idle":"2023-10-04T11:50:01.680670Z","shell.execute_reply.started":"2023-10-04T11:50:01.671866Z","shell.execute_reply":"2023-10-04T11:50:01.679817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree Regressor Model:\n","metadata":{"id":"kz9-TxPXCFKx"}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\ndt_regressor = DecisionTreeRegressor(random_state=42)\n# Create a Decision Tree Regressor instance\ndt_regressor = DecisionTreeRegressor(random_state=42)\n\n# Train the Decision Tree Regressor on your training data\ndt_regressor.fit(x_train, y_train)","metadata":{"id":"wbdJOK8G_gO6","outputId":"1f873ef2-15dc-4fb2-839a-4ec8aec7f9ac","execution":{"iopub.status.busy":"2023-10-04T11:50:01.681758Z","iopub.execute_input":"2023-10-04T11:50:01.682300Z","iopub.status.idle":"2023-10-04T11:50:01.819681Z","shell.execute_reply.started":"2023-10-04T11:50:01.682272Z","shell.execute_reply":"2023-10-04T11:50:01.818887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = dt_regressor.predict(x_test)\nprint(\"Predicted Values:\", y_pred)","metadata":{"id":"L_rrmok2Cdpt","outputId":"6e61eafa-c3d2-4698-e828-6c288d2cc029","execution":{"iopub.status.busy":"2023-10-04T11:50:01.820952Z","iopub.execute_input":"2023-10-04T11:50:01.821426Z","iopub.status.idle":"2023-10-04T11:50:01.828510Z","shell.execute_reply.started":"2023-10-04T11:50:01.821399Z","shell.execute_reply":"2023-10-04T11:50:01.827664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\n\n# Print the metrics\nprint(\"Decision Tree Regressor Metrics: \")\nprint(\"Mean Absolute Error (MAE):\", mae)\nprint(\"Mean Squared Error (MSE):\", mse)\nprint(\"Root Mean Squared Error (RMSE):\", rmse)\nprint(\"R-squared (R2) Score:\", r2)","metadata":{"id":"nH-Mpo_ICmLv","outputId":"ddae21fc-6548-4026-ff1a-3dadf7e7ca55","execution":{"iopub.status.busy":"2023-10-04T11:50:01.829461Z","iopub.execute_input":"2023-10-04T11:50:01.829736Z","iopub.status.idle":"2023-10-04T11:50:01.842174Z","shell.execute_reply.started":"2023-10-04T11:50:01.829716Z","shell.execute_reply":"2023-10-04T11:50:01.841468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualization Decision Tree Regressor:\n","metadata":{"id":"AcxcwETACy4w"}},{"cell_type":"code","source":"from sklearn.tree import plot_tree\n\n# Plot the Decision Tree\nplt.figure(figsize=(12, 6))\nplot_tree(dt_regressor, filled=True, feature_names=x_train.columns)\nplt.show()","metadata":{"id":"HC7GKFPLCs8R","outputId":"0ab8a4e9-eeb6-40fb-8da9-99b135dd6d2d","execution":{"iopub.status.busy":"2023-10-04T11:50:01.842923Z","iopub.execute_input":"2023-10-04T11:50:01.843571Z","iopub.status.idle":"2023-10-04T11:50:18.642842Z","shell.execute_reply.started":"2023-10-04T11:50:01.843550Z","shell.execute_reply":"2023-10-04T11:50:18.642028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KNeighborsRegressor:","metadata":{"id":"WDjO4CbLDE27"}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nknn_regressor = KNeighborsRegressor(n_neighbors=5)\nknn_regressor.fit(x_train, y_train)","metadata":{"id":"HhrJoRZADRc1","outputId":"bef0bf17-6d3d-4269-e3a5-92e3ca679188","execution":{"iopub.status.busy":"2023-10-04T11:50:18.644004Z","iopub.execute_input":"2023-10-04T11:50:18.644312Z","iopub.status.idle":"2023-10-04T11:50:18.655057Z","shell.execute_reply.started":"2023-10-04T11:50:18.644286Z","shell.execute_reply":"2023-10-04T11:50:18.654191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=knn_regressor.predict(x_test)\nprint('Predicted Values: ', y_pred)","metadata":{"id":"ySwAFjYjDfht","outputId":"3ef8c6ab-aa63-4ec0-e66c-9cde612e3141","execution":{"iopub.status.busy":"2023-10-04T11:50:18.655996Z","iopub.execute_input":"2023-10-04T11:50:18.656216Z","iopub.status.idle":"2023-10-04T11:50:18.681212Z","shell.execute_reply.started":"2023-10-04T11:50:18.656198Z","shell.execute_reply":"2023-10-04T11:50:18.680279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2_knr = r2_score(y_test, y_pred)\n\n# Print the metrics\nprint(\"KNeighborsRegressor Metrics: \")\nprint(\"Mean Absolute Error (MAE):\", mae)\nprint(\"Mean Squared Error (MSE):\", mse)\nprint(\"Root Mean Squared Error (RMSE):\", rmse)\nprint(\"R-squared (R2) Score:\", r2_knr)","metadata":{"id":"6gg4GDodDt46","outputId":"fc99403e-20b0-4a51-96d1-5dac2d0a682b","execution":{"iopub.status.busy":"2023-10-04T11:50:18.682248Z","iopub.execute_input":"2023-10-04T11:50:18.682848Z","iopub.status.idle":"2023-10-04T11:50:18.695796Z","shell.execute_reply.started":"2023-10-04T11:50:18.682827Z","shell.execute_reply":"2023-10-04T11:50:18.694943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GradientBoostingRegressor:","metadata":{"id":"p3Jmg9xJEEs3"}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n# Create a Gradient Boosting Regressor instance with specified hyperparameters\ngb_regressor = GradientBoostingRegressor(\n    n_estimators=100,  # Number of boosting stages to be used\n    learning_rate=0.1,  # Learning rate (step size shrinkage)\n    max_depth=3,  # Maximum depth of individual estimators\n    random_state=42\n)\n\n# Train the Gradient Boosting Regressor on your training data\ngb_regressor.fit(x_train, y_train)","metadata":{"id":"DXGQF0KnD3yR","outputId":"37bf08aa-a38d-4cce-ee33-985576a747e6","execution":{"iopub.status.busy":"2023-10-04T11:50:18.696774Z","iopub.execute_input":"2023-10-04T11:50:18.697025Z","iopub.status.idle":"2023-10-04T11:50:18.893229Z","shell.execute_reply.started":"2023-10-04T11:50:18.697006Z","shell.execute_reply":"2023-10-04T11:50:18.892215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=gb_regressor.predict(x_test)\nprint(\"Predicted Values: \", y_pred)","metadata":{"id":"HVINQJ78ENwQ","outputId":"a91d8ad6-a1ca-4a2b-dffe-4ec958f97a07","execution":{"iopub.status.busy":"2023-10-04T11:50:18.894466Z","iopub.execute_input":"2023-10-04T11:50:18.895167Z","iopub.status.idle":"2023-10-04T11:50:18.901960Z","shell.execute_reply.started":"2023-10-04T11:50:18.895143Z","shell.execute_reply":"2023-10-04T11:50:18.901095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2_gbr = r2_score(y_test, y_pred)\n\n# Print the metrics\nprint(\"GradientBoostingRegressor Metrics: \")\nprint(\"Mean Absolute Error (MAE):\", mae)\nprint(\"Mean Squared Error (MSE):\", mse)\nprint(\"Root Mean Squared Error (RMSE):\", rmse)\nprint(\"R-squared (R2) Score:\", r2_gbr)","metadata":{"id":"YEbMcrLiEfpX","outputId":"ecb0ce2f-cdd5-4f76-f1fe-90c8dc7ba1f5","execution":{"iopub.status.busy":"2023-10-04T11:50:18.903167Z","iopub.execute_input":"2023-10-04T11:50:18.903493Z","iopub.status.idle":"2023-10-04T11:50:18.916190Z","shell.execute_reply.started":"2023-10-04T11:50:18.903464Z","shell.execute_reply":"2023-10-04T11:50:18.915264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display, HTML\n\n# Create a DataFrame with the metrics\nmetrics_data = {\n    'Model': ['Linear Regression', 'SVR (SVM)', 'Decision Tree', 'K-Neighbors', 'Gradient Boosting'],\n    'MAE': [0.1037, 0.0984, 0.1317, 0.1288, 0.1037],\n    'MSE': [0.0249, 0.0236, 0.0361, 0.0314, 0.0249],\n    'RMSE': [0.1579, 0.1536, 0.1901, 0.1773, 0.1579],\n    'R² Score': [0.8326, 0.8416, 0.7574, 0.7888, 0.8326]\n}\n\nmetrics_df = pd.DataFrame(metrics_data)\n\n# Display the DataFrame as an HTML table\ndisplay(HTML(metrics_df.to_html()))","metadata":{"id":"dHbEoejoEmXh","outputId":"d6ca7c29-271a-41b0-c6e6-5641c773ade1","execution":{"iopub.status.busy":"2023-10-04T11:50:18.917337Z","iopub.execute_input":"2023-10-04T11:50:18.917580Z","iopub.status.idle":"2023-10-04T11:50:18.930476Z","shell.execute_reply.started":"2023-10-04T11:50:18.917561Z","shell.execute_reply":"2023-10-04T11:50:18.929961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. **SVR (SVM Model) appears to be the best-performing model** based on the R² (R-squared) score. It achieved the highest R² score of 0.8416 on the validation set, indicating that it explains the most variance in the target variable. This suggests that SVR provides a strong fit to the data and effectively captures the underlying patterns.\n\n2. **Linear Regression and Gradient Boosting Regressor** also performed well, with R² scores of 0.8326. These models provide good explanations of the variance in the target variable and are competitive choices.\n\n3. **K-Neighbors Regressor** performed slightly below the top models, with an R² score of 0.7888. While it still provides a reasonable fit, it may not capture as much variance as the top models.\n\n4. **Decision Tree Regressor** achieved the lowest R² score of 0.7574, indicating that it explained less variance in the target variable compared to the other models. It may be more prone to overfitting or may not capture the underlying patterns as effectively.\n\nIn conclusion, **SVR (SVM Model) is recommended as the best model for this regression task**, as it consistently achieved the highest R² score, signifying its ability to explain the most variance in the target variable. However, the choice of the best model should also consider other factors, including model complexity, interpretability, and domain-specific requirements. It's advisable to further validate the selected model on a separate test dataset to confirm its performance on unseen data.","metadata":{"id":"UqKTmuDDHA-c"}},{"cell_type":"markdown","source":"### Model Comparision Visualization:","metadata":{"id":"kjheQIqWIxY7"}},{"cell_type":"code","source":"linear_regression_scores = [0.8326, 0.8326, 0.8326, 0.8326, 0.8326]\nsvr_scores = [0.8416, 0.8416, 0.8416, 0.8416, 0.8416]\ndecision_tree_scores = [0.7574, 0.7574, 0.7574, 0.7574, 0.7574]\nk_neighbors_scores = [0.7888, 0.7888, 0.7888, 0.7888, 0.7888]\ngradient_boosting_scores = [0.8326, 0.8326, 0.8326, 0.8326, 0.8326]\n\n# Create a DataFrame with the example scores\nscores_map = {\n    'Linear Regression': linear_regression_scores,\n    'SVR (SVM)': svr_scores,\n    'Decision Tree': decision_tree_scores,\n    'K-Neighbors': k_neighbors_scores,\n    'Gradient Boosting': gradient_boosting_scores\n}\n\nscores_df = pd.DataFrame(scores_map)\n\n# Create a boxplot to visualize model performance with improved styling\nplt.figure(figsize=(12, 8))\nsns.set(style=\"whitegrid\")  # Set a white grid background\nax = sns.boxplot(data=scores_df, palette=\"viridis\")  # Use a color palette for boxes\nplt.title(\"Model Performance Comparison\", fontsize=16)\nplt.ylabel(\"R-squared (R2) Score\", fontsize=14)\nplt.xlabel(\"Regression Models\", fontsize=14)\nplt.xticks(rotation=45, ha='right', fontsize=12)\nplt.yticks(fontsize=12)\nplt.tight_layout()\nplt.show()","metadata":{"id":"uZ_-AkdQGqGg","outputId":"3911d961-ee19-4881-fd94-7f214c341634","execution":{"iopub.status.busy":"2023-10-04T11:50:18.934696Z","iopub.execute_input":"2023-10-04T11:50:18.935014Z","iopub.status.idle":"2023-10-04T11:50:19.311541Z","shell.execute_reply.started":"2023-10-04T11:50:18.934994Z","shell.execute_reply":"2023-10-04T11:50:19.310760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The **Support Vector Regression (SVR) model** was chosen for this project due to its ability to handle both linear and non-linear relationships in the data, making it suitable for predicting house prices, which often exhibit complex patterns. SVR is also effective in handling high-dimensional datasets and has been widely used in real estate prediction tasks, making it a robust choice for accurate price forecasting.\n* Visit the [Boston House Price ML Predictor](https://boston-house-price-ml-predictor-saimanoj.streamlit.app/) web application.","metadata":{}}]}